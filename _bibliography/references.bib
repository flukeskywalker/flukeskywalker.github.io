---
---
References
==========
@mastersthesis{hochreiter1991,
  title = {{Untersuchungen zu dynamischen neuronalen Netzen}},
  author = {Hochreiter, Sepp},
  year = {1991},
  address = {{M\"unchen}},
  language = {German},
  school = {Technische Universit\"at M\"unchen},
  type = {{Masters Thesis}}
}

@article{salimans2017,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@inproceedings{lehman2018,
  title={Safe mutations for deep and recurrent neural networks through output gradients},
  author={Lehman, Joel and Chen, Jay and Clune, Jeff and Stanley, Kenneth O},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={117--124},
  year={2018},
  organization={ACM}
}

@article{zhang2017,
  title={On the relationship between the {OpenAI} evolution strategy and stochastic gradient descent},
  author={Zhang, Xingwen and Clune, Jeff and Stanley, Kenneth O},
  journal={arXiv preprint arXiv:1712.06564},
  year={2017}
}

@inproceedings{lehman2018b,
  title={{ES} is more than just a traditional finite-difference approximator},
  author={Lehman, Joel and Chen, Jay and Clune, Jeff and Stanley, Kenneth O},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={450--457},
  year={2018},
  organization={ACM}
}

@inproceedings{conti2018,
  title={Improving exploration in evolution strategies for deep reinforcement learning via a population of novelty-seeking agents},
  author={Conti, Edoardo and Madhavan, Vashisht and Such, Felipe Petroski and Lehman, Joel and Stanley, Kenneth and Clune, Jeff},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5027--5038},
  year={2018}
}


@inproceedings{freeman2019,
  title={Learning to Predict Without Looking Ahead: World Models Without Forward Prediction},
  author={Freeman, Daniel and Ha, David and Metz, Luke},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5380--5391},
  year={2019}
}

@inproceedings{mania2018,
  title={Simple random search of static linear policies is competitive for reinforcement learning},
  author={Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1800--1809},
  year={2018}
}

@inproceedings{rajeswaran2017,
  title={Towards generalization and simplicity in continuous control},
  author={Rajeswaran, Aravind and Lowrey, Kendall and Todorov, Emanuel V and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6550--6561},
  year={2017}
}

@inproceedings{van2016,
  title={A wavelet-based encoding for neuroevolution},
  author={van Steenkiste, Sjoerd and Koutn{\'\i}k, Jan and Driessens, Kurt and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={517--524},
  year={2016},
  organization={ACM}
}

@article{ha2019,
  author = {Ha, David},
  title = {Reinforcement Learning for Improving Agent Design},
  journal = {Artificial Life},
  volume = {25},
  number = {4},
  pages = {352-365},
  year = {2019},
  doi = {10.1162/artl\_a\_00301},
  note ={PMID: 31697584},
  URL = {https://doi.org/10.1162/artl_a_00301},
  eprint = {https://doi.org/10.1162/artl_a_00301}
}

@misc{ha2017,
  title   = "A Visual Guide to Evolution Strategies",
  author  = "Ha, David",
  year    = "2017",
  howpublished = {\url{http://blog.otoro.net/2017/10/29/visual-evolution-strategies/}}
}

@misc{ha2017b,
  title   = "Evolving Stable Strategies",
  author  = "Ha, David",
  year    = "2017",
  howpublished = "http://blog.otoro.net/2017/11/12/evolving-stable-strategies/"
}

% Natural Evolution Strategies
@article{wierstra2014,
  title={Natural evolution strategies},
  author={Wierstra, Daan and Schaul, Tom and Glasmachers, Tobias and Sun, Yi and Peters, Jan and Schmidhuber, J{\"u}rgen},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={949--980},
  year={2014},
  publisher={JMLR.org}
}

% The popular CMAES paper
@article{hansen2001,
  title={Completely derandomized self-adaptation in evolution strategies},
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  journal={Evolutionary computation},
  volume={9},
  number={2},
  pages={159--195},
  year={2001},
  publisher={MIT Press}
}

% The original CMAES paper. Has covariance matrix adaptation and center-of-mass recombination, evolution path.
@article{hansen1997,
  title={Convergence properties of evolution strategies with the derandomized covariance matrix adaptation: The ($\mu$/$\mu_{I}$,$\lambda$)-CMA-ES},
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  journal={Eufit},
  volume={97},
  pages={650--654},
  year={1997},
  publisher={Citeseer}
}

% The original PGPE paper
@article{sehnke2010,
  title={Parameter-exploring policy gradients},
  author={Sehnke, Frank and Osendorfer, Christian and R{\"u}ckstie{\ss}, Thomas and Graves, Alex and Peters, Jan and Schmidhuber, J{\"u}rgen},
  journal={Neural Networks},
  volume={23},
  number={4},
  pages={551--559},
  year={2010},
  publisher={Elsevier}
}


% http://incompleteideas.net/book/the-book-2nd.html
@Book{sutton2018,
  author =    { Richard S. Sutton and Andrew G. Barto },
  title =     { Reinforcement Learning: An Introduction },
  edition =   { second },
  year =      { 2018 },
  publisher = { {MIT} Press, Cambridge, 2018 }
}


% A comprehensive metaheuristics book
@Book{luke2013,
  author =    { Sean Luke },
  title =     { Essentials of Metaheuristics },
  edition =   { second },
  year =      { 2013 },
  publisher = { Lulu },
  note =      { Available for free at http://cs.gmu.edu/$\sim$sean/book/metaheuristics/ }
}


% Paper of NSGAII
@article{deb2002,
  title={A fast and elitist multiobjective genetic algorithm: NSGA-II},
  author={Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, TAMT},
  journal={IEEE transactions on evolutionary computation},
  volume={6},
  number={2},
  pages={182--197},
  year={2002},
  publisher={IEEE}
}


% Paper of DEAP
@article{fortin2012,
  title={DEAP: Evolutionary algorithms made easy},
  author={Fortin, F{\'e}lix-Antoine and Rainville, Fran{\c{c}}ois-Michel De and Gardner, Marc-Andr{\'e} and Parizeau, Marc and Gagn{\'e}, Christian},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={Jul},
  pages={2171--2175},
  year={2012}
}


% GECCO EvoSoft 2017 paper for ECJ
@inproceedings{luke2017,
  title={{ECJ} then and now},
  author={Luke, Sean},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={1223--1230},
  year={2017}
}

% ECJ manual
@article{luke2019,
  title={The {ECJ} owner's manual},
  author={Sean Luke},
  note={https://cs.gmu.edu/~eclab/projects/ecj/manual.pdf},
  year={2019}
}

% GECCO EvoSoft 2019 paper for ECJ
@inproceedings{scott2019,
  title={{ECJ} at 20: Toward a General Metaheuristics Toolkit},
  author={Eric Scott and Sean Luke},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={1223--1230},
  year={2017}
}


% The first genetic algorithm book
@Book{holland1975,
  author =    { John Holland },
  title =     { Adaptation in Natural and Artificial Systems },
  year =      { 1975 },
  publisher = { University of Michigan Press }
}


% An old genetic algorithm article that can be used as a reference
@article{holland1992,
  title={Genetic algorithms},
  author={Holland, John H},
  journal={Scientific american},
  volume={267},
  number={1},
  pages={66--73},
  year={1992},
  publisher={JSTOR}
}


% The original evolution strategy paper
@incollection{rechenberg1978,
  title={Evolutionsstrategien},
  author={Rechenberg, Ingo},
  booktitle={Simulationsmethoden in der Medizin und Biologie},
  pages={83--114},
  year={1978},
  publisher={Springer}
}


% Early random search method sampling from a hypersphere (one sample at a time)
@article{rastrigin1963,
  title={The convergence of the random search method in the extremal control of a many parameter system},
  author={Rastrigin, L.A.},
  journal={Automation and Remote Control},
  volume={24},
  number={10},
  pages={1337â€“-1342},
  year={1963}
}


% Early random optimization technique sampling from a Gaussian distribution (one sample at a time)
@article{matyas1965,
  title={Random optimization},
  author={M\'aty\'a{\v s}, I.},
  journal={Automation and Remote Control},
  volume={26},
  number={2},
  pages={246--253},
  year={1965}
}


% Simulated binary cross-over
@article{deb2001self,
  title={Self-adaptive genetic algorithms with simulated binary crossover},
  author={Deb, Kalyanmoy and Beyer, Hans-Georg},
  journal={Evolutionary computation},
  volume={9},
  number={2},
  pages={197--221},
  year={2001},
  publisher={MIT Press}
}

@inproceedings{henderson2018,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

% OpenAI gym
@article{brockman2016,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

% PyTorch
@incollection{paszke2019,
title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
author = {Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas K\"{o}pf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.}
}
%author = {Paszke, Adam and Gross, Sam and Massa, Francisco and others},
%url = {http://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}

% ray
@inproceedings{moritz2018,
  title={Ray: A distributed framework for emerging {AI} applications},
  author={Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I. Jordan and Ion Stoica},
  booktitle={13th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 18)},
  pages={561--577},
  year={2018}
}

% rllib
@article{liang2017,
  title={Rllib: Abstractions for distributed reinforcement learning},
  author={Liang, Eric and Liaw, Richard and Moritz, Philipp and Nishihara, Robert and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph E and Jordan, Michael I and Stoica, Ion},
  journal={arXiv preprint arXiv:1712.09381},
  year={2017}
}

% EO (Evolving Objects Library)
@article{keijzer2001,
  title =     "Evolving Objects: A General Purpose Evolutionary Computation Library ",
  author =    "Maarten Keijzer and J. J. Merelo and G. Romero and M. Schoenauer",
  journal =   "Artificial Evolution",
  year =      "2002",
  volume =    "2310",
  pages =     "829--888",
  keywords =  "genetic algorithms, genetic programming, evolutionary computation, metaheuristic, computational intelligence, optimization",
  URL =       "http://www.lri.fr/~marc/EO/EO-EA01.ps.gz"
}

% ParadisEO
@article{cahon2004,
  title={Paradiseo: A framework for the reusable design of parallel and distributed metaheuristics},
  author={Cahon, S{\'e}bastien and Melab, Nordine and Talbi, E-G},
  journal={Journal of heuristics},
  volume={10},
  number={3},
  pages={357--380},
  year={2004},
  publisher={Springer}
}

% OpenBEAGLE
@article{gagne2006,
    author    = { Christian Gagn\'e and Marc Parizeau },
    title     = { Genericity in Evolutionary Computation Software Tools:
		          Principles and Case Study },
    volume    = { 15 },
    number    = { 2 },
    pages     = { 173--194 },
    year      = { 2006 },
    journal   = { International Journal on Artificial Intelligence Tools }
}

% pycma
@misc{hansen2019,
  author       = {Nikolaus Hansen and Youhei Akimoto and Petr Baudis},
  title        = {{CMA-ES/pycma} on {G}ithub},
  howpublished = {Zenodo, DOI:10.5281/zenodo.2559634},
  month        = feb,
  year         = 2019,
  doi          = {10.5281/zenodo.2559634},
  url          = {https://doi.org/10.5281/zenodo.2559634},
}

% sacred
@inproceedings{greff2017,
  title={The sacred infrastructure for computational research},
  author={Greff, Klaus and Klein, Aaron and Chovanec, Martin and Hutter, Frank and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the Python in Science Conferences-SciPy Conferences},
  year={2017}
}

% batchnorm
@inproceedings{ioffe2015,
  title={Batch normalization: Accelerating deep network trainingby reducing internal covariate shift},
  author={Sergey Ioffe and Christian Szegedy},
  booktitle={Proceedings of the 32nd International Conference on Machine Learning},
  pages={448--456},
  year={2015}
}

%Adam
@inproceedings{kingma2015,
  title={Adam: A method for stochastic optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  booktitle={Proceedings of 3rd International Conference on Learning Representations},
  year={2015}
}

%RAdam
@inproceedings{reddi2018,
  title={On the convergence of {Adam} and beyond},
  author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
  booktitle={Proceedings of 6th International Conference on Learning Representations},
  year={2018}
}

%Classical momentum
@article{polyak1964,
  title={Some methods of speeding up the convergence of iteration methods},
  author={Polyak, Boris T},
  journal={USSR Computational Mathematics and Mathematical Physics},
  volume={4},
  number={5},
  pages={1--17},
  year={1964},
  publisher={Elsevier}
}

%mujoco
@inproceedings{todorov2012,
author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
year = {2012},
month = {10},
pages = {5026--5033},
title = {MuJoCo: A physics engine for model-based control},
isbn = {978-1-4673-1737-5},
booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2012.6386109}
}

%pybullet
@MISC{coumans2019,
author =   {Erwin Coumans and Yunfei Bai},
title =    {PyBullet, a Python module for physics simulation for games, robotics and machine learning},
howpublished = {\url{http://pybullet.org}},
year = {2016--2019}
}

%mujoco humanoid
@inproceedings{tassa2012,
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4906--4913},
  year={2012},
  organization={IEEE}
}

%mujoco hopper
@inproceedings{erez2011,
  author    = {Tom Erez and
               Yuval Tassa and
               Emanuel Todorov},
  editor    = {Hugh F. Durrant{-}Whyte and
               Nicholas Roy and
               Pieter Abbeel},
  title     = {Infinite-Horizon Model Predictive Control for Periodic Tasks with Contacts},
  booktitle = {Robotics: Science and Systems VII, University of Southern California,
               Los Angeles, CA, USA, June 27-30, 2011},
  year      = {2011},
  url       = {http://www.roboticsproceedings.org/rss07/p10.html},
  doi       = {10.15607/RSS.2011.VII.010},
  timestamp = {Wed, 26 Jun 2019 18:00:01 +0200},
  biburl    = {https://dblp.org/rec/conf/rss/ErezTT11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%mujoco ant
%%article{schulman2015high,
%  title={High-dimensional continuous control using generalized advantage estimation},
%  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
%  journal={arXiv preprint arXiv:1506.02438},
%  year={2015}
%}
@inproceedings{schulman2016,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  booktitle={Proceedings of 4th International Conference on Learning Representations},
  year={2016}
}

%roboschool
@misc{klimov2017,
  title   = {Roboschool},
  author  = {Oleg Klimov and John Schulman},
  journal = {OpenAI blog},
  year    = {2017},
  howpublished     = {\url{https://openai.com/blog/roboschool/}}
}

%antithetic sampling
@article{geweke1988,
  title={Antithetic acceleration of Monte Carlo integration in Bayesian inference},
  author={Geweke, John},
  journal={Journal of Econometrics},
  volume={38},
  number={1-2},
  pages={73--89},
  year={1988},
  publisher={Elsevier}
}

%mirrored sampling
@inproceedings{brockhoff2010,
  title={Mirrored sampling and sequential selection for evolution strategies},
  author={Brockhoff, Dimo and Auger, Anne and Hansen, Nikolaus and Arnold, Dirk V and Hohm, Tim},
  booktitle={International Conference on Parallel Problem Solving from Nature},
  pages={11--21},
  year={2010},
  organization={Springer}
}

%inverse mutation, equivalent of mirrored sampling
@inproceedings{salomon2005,
  title={Inverse Mutations: Making the Evolutionary-Gradient-Search Procedure Noise Robust},
  author={Salomon, Ralf},
  booktitle={Proceedings of the {IASTED} International Conference on Artificial Intelligence and Applications},
  pages={322--327},
  year={2005}
}

%evolutionary gradient search
@article{salomon1998,
  title={Evolutionary algorithms and gradient search: similarities and differences},
  author={Salomon, Ralf},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={2},
  number={2},
  pages={45--55},
  year={1998},
  publisher={IEEE}
}

% PaGMO software ref
@software{francesco_biscani_2020_3603747,
  author       = {Francesco Biscani and Dario Izzo},
  title        = {esa/pagmo2: pagmo 2.13.0},
  month        = jan,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {v2.13.0},
  doi          = {10.5281/zenodo.3603747},
  url          = {https://doi.org/10.5281/zenodo.3603747}
}

% PaGMO paper
@article{biscani2010global,
  title={A global optimisation toolbox for massively parallel engineering optimisation},
  author={Biscani, Francesco and Izzo, Dario and Yam, Chit Hong},
  journal={arXiv preprint arXiv:1004.3824},
  year={2010}
}

% generalized island models
@Inbook{Izzo2012,
author="Izzo, Dario
and Ruci{\'{n}}ski, Marek
and Biscani, Francesco",
editor="Fern{\'a}ndez de Vega, Francisco
and Hidalgo P{\'e}rez, Jos{\'e} Ignacio
and Lanchares, Juan",
title="The Generalized Island Model",
bookTitle="Parallel Architectures and Bioinspired Algorithms",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="151--169",
abstract="The island model paradigm allows to efficiently distribute genetic algorithms overmultiple processors while introducing a new genetic operator, themigration operator, able to improve the overall algortihmic performance. In this chapter we introduce the generalized island model that can be applied to a broad class of optimization algorithms. First, we study the effect of such a generalized distribution model on several well-known global optimizationmetaheuristics.We consider some variants of Differential Evolution, Genetic Algorithms, Harmony Search, Artificial Bee Colony, Particle Swarm Optimization and Simulated Annealing. Based on an set of 12 benchmark problems we show that in the majority of cases introduction of the migration operator leads to obtaining better results than using an equivalent multi-start scheme.We then apply the generalized island model to construct heterogeneous ``archipelagos'', which employ different optimization algorithms on different islands, and show cases where this leads to further improvements of performance with respect to the homogeneous case.",
isbn="978-3-642-28789-3",
doi="10.1007/978-3-642-28789-3_7",
url="https://doi.org/10.1007/978-3-642-28789-3_7"
}

% DQN
@article{mnih2015,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

% DDPG
@article{lillicrap2015,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

% TRPO
@inproceedings{schulman2015,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

% SAC
@article{haarnoja2018,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

% PPO
@article{schulman2017,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

% Optimizers
@inproceedings{sutskever2013,
  title={On the importance of initialization and momentum in deep learning},
  author={Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1139--1147},
  year={2013}
}

% Gradient clipping
@inproceedings{pascanu2013,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013}
}

% Gradient clipping 2
@inproceedings{zhang2020,
  title={Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity},
  author={Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

% Gradient clipping 3
@article{graves2013a,
  title = {Generating Sequences with Recurrent Neural Networks},
  author = {Graves, Alex},
  year = {2013},
  url = {https://arxiv.org/abs/1308.0850},
  journal = {arXiv preprint arXiv:1308.0850}
}

% Gradient clipping 4
@phdthesis{mikolov2012a,
  title = {Statistical Language Models Based on Neural Networks},
  author = {Mikolov, Tom{\'a}{\v s}},
  year = {2012},
  address = {{Brno, Czech Republic}},
  school = {Brno University of Technology},
  type = {{{PhD Thesis}}}
}




% REINFORCE
@article{williams1992,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

% rl-zoo
@misc{raffin2018,
  author = {Raffin, Antonin},
  title = {RL Baselines Zoo},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {https://github.com/araffin/rl-baselines-zoo},
}

@misc{coumans2018note,
  author = {Erwin Coumans},
  title = {PyBullet repository -- Issues},
  year = {2018},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/bulletphysics/bullet3/issues/1718\#issuecomment-393198883}}
}

@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}

@phdthesis{sehnke2012parameter,
  title={Parameter exploring policy gradients and their implications},
  author={Sehnke, Frank},
  year={2012},
  school={Technische Universit{\"a}t M{\"u}nchen}
}

% AdaGrad
@article{duchi2011,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

% Surveys on usage of evolution for RL
@incollection{whiteson2012,
  title={Evolutionary computation for reinforcement learning},
  author={Whiteson, Shimon},
  booktitle={Reinforcement learning},
  pages={325--355},
  year={2012},
  publisher={Springer}
}

@article{moriarty1999,
  title={Evolutionary algorithms for reinforcement learning},
  author={Moriarty, David E and Schultz, Alan C and Grefenstette, John J},
  journal={Journal of Artificial Intelligence Research},
  volume={11},
  pages={241--276},
  year={1999}
}

@article{choi2019empirical,
  title={On Empirical Comparisons of Optimizers for Deep Learning},
  author={Choi, Dami and Shallue, Christopher J and Nado, Zachary and Lee, Jaehoon and Maddison, Chris J and Dahl, George E},
  journal={arXiv preprint arXiv:1910.05446},
  year={2019}
}

% Python 3
@book{vanrossum2009,
 author = {{Van Rossum}, Guido and Drake, Fred L.},
 title = {Python 3 Reference Manual},
 year = {2009},
 isbn = {1441412697},
 publisher = {CreateSpace},
 address = {Scotts Valley, CA}
}

% SciPy
@ARTICLE{virtanen2020,
       author = {{Virtanen}, Pauli and {Gommers}, Ralf and {Oliphant}, Travis E. and {Haberland}, Matt and {Reddy}, Tyler and {Cournapeau}, David and {Burovski}, Evgeni and {Peterson}, Pearu and {Weckesser}, Warren and {Bright}, Jonathan and {van der Walt}, St{\'e}fan J.  and {Brett}, Matthew and {Wilson}, Joshua and {Jarrod Millman}, K.  and {Mayorov}, Nikolay and {Nelson}, Andrew R.~J. and {Jones}, Eric and {Kern}, Robert and {Larson}, Eric and {Carey}, CJ and {Polat}, {\.I}lhan and {Feng}, Yu and {Moore}, Eric W. and {Vand erPlas}, Jake and {Laxalde}, Denis and {Perktold}, Josef and {Cimrman}, Robert and {Henriksen}, Ian and {Quintero}, E.~A. and {Harris}, Charles R and {Archibald}, Anne M. and {Ribeiro}, Ant{\^o}nio H. and {Pedregosa}, Fabian and {van Mulbregt}, Paul and {Contributors}},
        title = "{SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python}",
      journal = {Nature Methods},
      year = "2020",
      volume={17},
      pages={261--272},
      adsurl = {https://rdcu.be/b08Wh},
      doi = {https://doi.org/10.1038/s41592-019-0686-2}
}

% NumPy
@book{oliphant2006,
  title={A guide to NumPy},
  author={Oliphant, Travis E},
  volume={1},
  year={2006},
  publisher={Trelgol Publishing USA}
}
